{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDO0WibX8h3O"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import glob\n",
        "import pathlib\n",
        "import zipfile\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from pathlib import Path\n",
        "from keras.preprocessing import image\n",
        "\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive')\n",
        "\n",
        "# Set up Images in Datasets\n",
        "def extractDataSet(folder_path, labels, label_mode, image_size, batch_size, seed, shuffle, interpolation):\n",
        "    return tf.keras.utils.image_dataset_from_directory(\n",
        "        directory=folder_path,\n",
        "        labels=labels,\n",
        "        label_mode=label_mode,\n",
        "        image_size=image_size,\n",
        "        batch_size=batch_size,\n",
        "        interpolation=interpolation,\n",
        "        seed=seed,\n",
        "        shuffle=shuffle\n",
        "    )\n",
        "\n",
        "# Simple Model\n",
        "def simpleModel():\n",
        "      return Sequential([\n",
        "          #Convolution block #1\n",
        "          #Setting up convolution block\n",
        "          layers.Conv2D(32, (3, 3), activation='relu', input_shape=(512, 512, 3)),\n",
        "          #Adding Max Pooling\n",
        "          layers.MaxPooling2D((2, 2)),\n",
        "          #Setting up convolution block\n",
        "          layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "          #Adding Max Pooling layers.MaxPooling2D((2, 2)),\n",
        "          #Transition to Classification\n",
        "          layers.Flatten(),\n",
        "          #DNN layers.Dense(128, activation='relu'),\n",
        "          layers.Dense(5, activation='softmax')\n",
        "      ])\n",
        "\n",
        "# Print Accuracy And Loss\n",
        "def printAccuracyAndLoss(history, datasetName):\n",
        "    if datasetName == \"Training\":\n",
        "        print(f\"{datasetName} Accuracy: {history.history['accuracy'][-1]:.2f}\")\n",
        "        print(f\"{datasetName} Loss: {history.history['loss'][-1]:.2f}\")\n",
        "    elif datasetName == \"Validation\":\n",
        "        print(f\"{datasetName} Accuracy: {history.history['val_accuracy'][-1]:.2f}\")\n",
        "        print(f\"{datasetName} Loss: {history.history['val_loss'][-1]:.2f}\")\n",
        "\n",
        "\n",
        "# Plot Image\n",
        "def plotMetrics(epochs_range, training_metric, val_metric, training_label, val_label, title):\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs_range, training_metric, label=training_label)\n",
        "    plt.plot(epochs_range, val_metric, label=val_label)\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title(title)\n",
        "\n",
        "# Diplay Image\n",
        "def display_image(image_path):\n",
        "    img = Image.open(str(image_path))\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "#Predict Image\n",
        "def predict_image(image_path):\n",
        "    test_image = image.load_img(image_path, target_size = (512, 512))\n",
        "    test_image = image.img_to_array(test_image)\n",
        "    test_image = np.expand_dims(test_image, axis = 0)\n",
        "    result = np.array(model.predict(test_image))\n",
        "    print(result)\n",
        "    if result[0][0] == 0:\n",
        "        prediction = '0'\n",
        "    elif result[0][0] == 1:\n",
        "        prediction = '1'\n",
        "    elif result[0][0] == 2:\n",
        "        prediction = '2'\n",
        "    elif result[0][0] == 3:\n",
        "        prediction = '3'\n",
        "    elif result[0][0] == 4:\n",
        "        prediction = '4'\n",
        "    else:\n",
        "        prediction = '0'\n",
        "\n",
        "    print(prediction)\n",
        "\n",
        "# Print Predicted vs. True Class Labels along with image\n",
        "def printPredictedAndTrueClassLabels(test_images, test_labels, model):\n",
        "    test_images_np = np.array(test_images)\n",
        "    #Predict image labels with provided model\n",
        "    predictions = model.predict(test_images_np, verbose=0)\n",
        "    print(predictions)\n",
        "    #Identify image labels from predictions and print\n",
        "    predicted_classes = np.argmax(predictions, axis=1)\n",
        "    print(predicted_classes)\n",
        "    #Identify true labels and print\n",
        "    true_classes = np.array(test_labels)\n",
        "    print(true_classes)\n",
        "    return true_classes, predicted_classes\n",
        "\n",
        "# Print Confusion Matrix and Classification Report\n",
        "def printConfusionMatrixAndClassificationReport(true_classes, predicted_classes):\n",
        "    # Classification Report\n",
        "    print('# Classification Report')\n",
        "    print(classification_report(true_classes, predicted_classes))\n",
        "    # Confusion Matrix\n",
        "    conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(conf_matrix)\n",
        "    # Heatmap visualization for confusion matrix\n",
        "    cm_display = ConfusionMatrixDisplay(confusion_matrix = conf_matrix, display_labels = [\"0\", \"1\", \"2\", \"3\", \"4\"])\n",
        "    # Display matrix\n",
        "    cm_display.plot()\n",
        "    # Save matrix to file\n",
        "    filename = f\"CNN_Simple_Model_Confusion_matrix_v1.png\"\n",
        "    full_path = os.path.join(DATA_PIPELINE_PATH, filename)\n",
        "\n",
        "    print(f\"  CNN Simple Model Confusion Matrix v1: {filename}\")\n",
        "    print(f\"Images saved to: {DATA_PIPELINE_PATH}\")\n",
        "    plt.tight_layout()\n",
        "    cm_display.figure_.savefig(full_path, bbox_inches='tight')\n",
        "\n",
        "    # --- Pipeline Begin ---\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Data Path\n",
        "    DATA_PIPELINE_PATH = '/data/processed/'\n",
        "    #DATA_PIPELINE_PATH = Path('/content/gdrive/MyDrive/AIML-Bootcamp/Colab_Data/Data_Pipeline')\n",
        "\n",
        "    # Set dataset parameters\n",
        "    image_size = (512, 512)\n",
        "    img_height = 512\n",
        "    img_width = 512\n",
        "    batch_size = 32\n",
        "    seed = 0\n",
        "    validation_split_ratio = 0 # 0% for validation, since the images are already split into train, test and val\n",
        "    interpolation=\"bilinear\"\n",
        "    labels=\"inferred\"\n",
        "    label_mode='int'\n",
        "    shuffle=True\n",
        "\n",
        "    # Load datasets\n",
        "    train_ds = extractDataSet(DATA_PIPELINE_PATH / 'train', labels, label_mode, image_size, batch_size, seed, True, interpolation)\n",
        "    test_ds = extractDataSet(DATA_PIPELINE_PATH / 'test', labels, label_mode, image_size, batch_size, seed, True, interpolation)\n",
        "    val_ds = extractDataSet(DATA_PIPELINE_PATH / 'val', labels, label_mode, image_size, batch_size, seed, False, interpolation)\n",
        "\n",
        "    # Simple Model\n",
        "    model = simpleModel()\n",
        "    model.summary()\n",
        "\n",
        "    # Compile Model\n",
        "    model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "    # Fit Model\n",
        "    epochs = 10\n",
        "    history = model.fit(\n",
        "        train_ds,\n",
        "        validation_data=val_ds,\n",
        "        epochs=epochs\n",
        "    )\n",
        "\n",
        "    # Print the training and validation accuracies\n",
        "    printAccuracyAndLoss(history, \"Training\")\n",
        "    printAccuracyAndLoss(history, \"Validation\")\n",
        "\n",
        "    epochs_range = range(epochs)\n",
        "\n",
        "    # Plot Training and Validation Accuracy\n",
        "    plotMetrics(epochs_range, history.history['accuracy'], history.history['val_accuracy'], 'Training Accuracy', 'Validation Accuracy', 'Training and Validation Accuracy')\n",
        "\n",
        "    # Plot Training and Validation Loss\n",
        "    plotMetrics(epochs_range, history.history['loss'], history.history['val_loss'], 'Training Loss', 'Validation Loss', 'Training and Validation Loss')\n",
        "\n",
        "    # Build Test images and labels\n",
        "    test_images = []\n",
        "    test_labels = []\n",
        "    for images, labels in test_ds:\n",
        "        test_images.extend(images.numpy())\n",
        "        test_labels.extend(labels.numpy())\n",
        "\n",
        "    # Calculate test accuracy\n",
        "    test_loss, test_accuracy = model.evaluate(test_ds, verbose=0)\n",
        "    print(f\"Test Accuracy: {test_accuracy:.3f} ({test_accuracy*100:.1f}%)\")\n",
        "    print(f\"Test Loss: {test_loss:.3f} ({test_loss:.1f}%)\")\n",
        "\n",
        "    # Display some images\n",
        "    # Get file paths from the test directory structure\n",
        "    test_image_files_list = []\n",
        "    test_extract_dir = DATA_PIPELINE_PATH / 'test'\n",
        "    test_image_extensions = (\"*/*.jpg\", \"*/*.jpeg\", \"*/*.png\", \"*/*.gif\", \"*/*.bmp\", \"*/*.tiff\")\n",
        "\n",
        "    for ext in test_image_extensions:\n",
        "        test_image_files_list.extend(glob.glob(os.path.join(test_extract_dir, ext)))\n",
        "\n",
        "    for i in range(30):\n",
        "      print(i)\n",
        "      display_image(test_image_files_list[i])\n",
        "      predict_image(test_image_files_list[i])\n",
        "\n",
        "    # Get predictions for test images\n",
        "    true_classes, predicted_classes = printPredictedAndTrueClassLabels(test_images, test_labels, model)\n",
        "\n",
        "    # Print Confusion Matrix And Classification Report\n",
        "    printConfusionMatrixAndClassificationReport(true_classes, predicted_classes)"
      ]
    }
  ]
}