{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDO0WibX8h3O",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#!pip install split-folders\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, utils\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "import splitfolders\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "# Set Color Pallette\n",
        "sns.set_palette(\"viridis\")\n",
        "\n",
        "# Organize image files from a main directory into another directory with subdirectories which are also classes for the images.\n",
        "def organize_images_by_class(csv_path, source_image_dir, destination_base_dir, image_col='id_code', class_col='diagnosis'):\n",
        "    try:\n",
        "        df = pd.read_csv(csv_path)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: CSV file not found at {csv_path}\")\n",
        "        return\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading CSV file: {e}\")\n",
        "        return\n",
        "\n",
        "    if image_col not in df.columns or class_col not in df.columns:\n",
        "        print(f\"Error: CSV must contain '{image_col}' and '{class_col}' columns.\")\n",
        "        return\n",
        "\n",
        "    # Create the base destination directory if it doesn't exist\n",
        "    os.makedirs(destination_base_dir, exist_ok=True)\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        image_filename = row[image_col]\n",
        "        image_filename = image_filename + '.png'\n",
        "        class_name = str(row[class_col]) # Ensure class_name is a string\n",
        "\n",
        "        source_path = os.path.join(source_image_dir, image_filename)\n",
        "        destination_class_dir = os.path.join(destination_base_dir, class_name)\n",
        "        destination_path = os.path.join(destination_class_dir, image_filename)\n",
        "\n",
        "        # Create class-specific subfolder if it doesn't exist\n",
        "        os.makedirs(destination_class_dir, exist_ok=True)\n",
        "\n",
        "        if os.path.exists(source_path):\n",
        "            try:\n",
        "                shutil.copy2(source_path, destination_path)\n",
        "                print(f\"Copied '{image_filename}' to '{destination_class_dir}'\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error copying '{image_filename}': {e}\")\n",
        "        else:\n",
        "            print(f\"Warning: Image file '{image_filename}' not found at '{source_path}'\")\n",
        "\n",
        "# Split Images into Train, Test and Validation folders\n",
        "def splitImagesIntoTrainTestVal(input_folder, output_folder):\n",
        "      # Create the output folder if it doesn't exist\n",
        "      os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "      # Split the data\n",
        "      # ratio=(train_ratio, validation_ratio, test_ratio)\n",
        "      splitfolders.ratio(input_folder, output=output_folder, seed=42, ratio=(0.7, 0.2, 0.1), group_prefix=None)\n",
        "      print(\"Image organization complete.\")\n",
        "\n",
        "# Delete Intermediate Directory\n",
        "def deleteIntermediateFolder(intermediate_dir):\n",
        "    if os.path.exists(intermediate_dir):\n",
        "        try:\n",
        "            shutil.rmtree(intermediate_dir)\n",
        "            print(f\"Deleted intermediate directory: {intermediate_dir}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error deleting intermediate directory '{intermediate_dir}': {e}\")\n",
        "    else:\n",
        "        print(f\"Intermediate directory '{intermediate_dir}' does not exist.\")\n",
        "\n",
        "# Set up Images in Datasets\n",
        "def extractDataSet(folder_path, labels, label_mode, image_size, batch_size, seed, shuffle, interpolation):\n",
        "    return tf.keras.utils.image_dataset_from_directory(\n",
        "        directory=folder_path,\n",
        "        labels=labels,\n",
        "        label_mode=label_mode,\n",
        "        image_size=image_size,\n",
        "        batch_size=batch_size,\n",
        "        interpolation=interpolation,\n",
        "        seed=seed,\n",
        "        shuffle=shuffle\n",
        "    )\n",
        "\n",
        "# Calculate Class Count in Dataset and print distribution\n",
        "def showClassDistribution(dataset, datasetName):\n",
        "    counts = Counter()\n",
        "    for features, labels in dataset:\n",
        "        # Convert labels to NumPy array for easier processing\n",
        "        train_labels_np = labels.numpy()\n",
        "        counts.update(train_labels_np)\n",
        "\n",
        "    print({datasetName}, \"Class distribution:\", dict(counts))\n",
        "    categories = list(counts.keys())\n",
        "    values = list(counts.values())\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.bar(categories, values)\n",
        "    plt.title(datasetName + \"Class Distribution\", fontsize=14)\n",
        "    plt.xlabel('Categories')\n",
        "    plt.ylabel('Values')\n",
        "    plt.xticks(rotation=90) # Rotate x-axis labels for better readability if needed\n",
        "    plt.tight_layout() # Adjust layout to prevent labels from overlapping\n",
        "\n",
        "    # Create the directory if it doesn't exist\n",
        "    if not os.path.exists(DATA_PIPELINE_PATH):\n",
        "        os.makedirs(DATA_PIPELINE_PATH)\n",
        "\n",
        "    # Create the full path to the file\n",
        "    filename = f\"{datasetName}_class_distribution.png\"\n",
        "    full_path = os.path.join(DATA_PIPELINE_PATH, filename)\n",
        "\n",
        "    print(f\"  Class Distribution For Dataset {datasetName}: {filename}\")\n",
        "    print(f\"Images saved to: {DATA_PIPELINE_PATH}\")\n",
        "    plt.tight_layout()\n",
        "    # Save file in the directory\n",
        "    plt.savefig(full_path)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Normalize images\n",
        "def normalize_img(image, label):\n",
        "    return tf.cast(image, tf.float32) / 255.0, label\n",
        "\n",
        "#Crop images and resize to original size\n",
        "def crop_image(image, label):\n",
        "    # Assuming images are in channels_last format (height, width, channels)\n",
        "    height, width = tf.shape(image)[0], tf.shape(image)[1]\n",
        "    size = tf.minimum(height, width)\n",
        "    offset_height = (height - size) // 2\n",
        "    offset_width = (width - size) // 2\n",
        "    cropped_image = tf.image.crop_to_bounding_box(\n",
        "        image,\n",
        "        offset_height,\n",
        "        offset_width,\n",
        "        size,\n",
        "        size\n",
        "    )\n",
        "    # Resize the cropped image back to the original image_size\n",
        "    resized_image = tf.image.resize(cropped_image, size=(image_size[0], image_size[1]))\n",
        "    return resized_image, label\n",
        "\n",
        "# Data Augmentation\n",
        "def data_augmentation(image, rotation_range, width_shift_range, height_shift_range, shear_range, zoom_range, horizontal_flip, fill_mode):\n",
        "    x = img_to_array(image)\n",
        "    x = np.expand_dims(x, axis=0) # Add batch dimension\n",
        "\n",
        "    # Create an ImageDataGenerator with desired augmentations\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range,\n",
        "        width_shift_range,\n",
        "        height_shift_range,\n",
        "        shear_range,\n",
        "        zoom_range,\n",
        "        horizontal_flip,\n",
        "        fill_mode\n",
        "    )\n",
        "\n",
        "    # Generate augmented images\n",
        "    i = 0\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    for batch in datagen.flow(x, batch_size=1):\n",
        "        plt.subplot(1, 5, i + 1)\n",
        "        plt.imshow(batch[0].astype('uint8'))\n",
        "        plt.axis('off')\n",
        "        i += 1\n",
        "        if i % 5 == 0: # Generate 5 augmented images for demonstration\n",
        "            break\n",
        "    plt.show()\n",
        "\n",
        "    return datagen.flow(1, batch_size=32)\n",
        "\n",
        "# Preprocess Images\n",
        "def preprocess_images(image, label):\n",
        "    normalize_img(image, label)\n",
        "    crop_image(image, label)\n",
        "    return image, label\n",
        "\n",
        "# Preview Images\n",
        "def previewImages(dataset, datasetName, path_to_save_images):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    print(len(dataset.take(1)))\n",
        "    class_names = [\"Class 0\", \"Class 1\", \"Class 2\", \"Class 3\", \"Class 4\"]\n",
        "\n",
        "    for images, labels in dataset.take(1):\n",
        "      for i in range(9):\n",
        "        if i < images.shape[0]:\n",
        "          ax = plt.subplot(3, 3, i + 1)\n",
        "          plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "          plt.title(class_names[labels[i]])\n",
        "          plt.axis(\"off\")\n",
        "\n",
        "    # Create the directory if it doesn't exist\n",
        "    if not os.path.exists(path_to_save_images):\n",
        "        os.makedirs(path_to_save_images)\n",
        "\n",
        "    # Create the full path to the file\n",
        "    filename = f\"{datasetName}_previewImages.png\"\n",
        "    full_path = os.path.join(path_to_save_images, filename)\n",
        "\n",
        "    print(f\"  Preview Images For Dataset {datasetName}: {filename}\")\n",
        "    print(f\"Images saved to: {path_to_save_images}\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    # Save file in the directory\n",
        "    plt.savefig(full_path)\n",
        "    plt.show()\n",
        "\n",
        "# Save Pre-processed dataset\n",
        "def saveImagesToFolder(dataset, path_to_save_images):\n",
        "    os.makedirs(path_to_save_images, exist_ok=True)\n",
        "\n",
        "    for i, (images, labels) in enumerate(dataset):\n",
        "        for j in range(images.shape[0]):\n",
        "            img_array = images[j].numpy()\n",
        "            label_val = labels[j].numpy()\n",
        "            os.makedirs(os.path.join(path_to_save_images / f\"{label_val}\"), exist_ok=True)\n",
        "            filename = f\"image_batch{i}_idx{j}_label{label_val}.png\"\n",
        "            print(\"Saving file {filename} to path: \", path_to_save_images / f\"{label_val}\")\n",
        "            tf.keras.utils.save_img(os.path.join(path_to_save_images / f\"{label_val}\", filename), img_array)\n",
        "\n",
        "    print(f\"Images saved to: {path_to_save_images}\")\n",
        "\n",
        "# --- Pipeline Begin ---\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Data Path\n",
        "    DATA_PIPELINE_PATH = '/data/processed'\n",
        "\n",
        "    # Organize images into folders by class/label\n",
        "    csv_file_path = '/healthcare/retinal_labels.csv'  # Path to your CSV file\n",
        "    image_source_directory = '/data/raw/retinal_images_256'  # Directory where your images are currently located\n",
        "    destination_root_directory = '/data/raw/Labeled_Images'  # Parent directory for your new subfolders\n",
        "\n",
        "    organize_images_by_class(csv_file_path, image_source_directory, destination_root_directory)\n",
        "    print(\"Image organization complete.\")\n",
        "\n",
        "    #Split Images into Train, Test and Val folders\n",
        "\n",
        "    # Define the input and output directories\n",
        "    input_folder = '/data/raw/Labeled_Images'  # Replace with the path to your original image folder\n",
        "    output_folder = '/data/raw/Train_Test_Val_Split_Images' # Replace with your desired output directory\n",
        "\n",
        "    splitImagesIntoTrainTestVal(input_folder, output_folder)\n",
        "\n",
        "    # Delete intermediate folder\n",
        "    intermediate_dir = '/data/raw/Labeled_Images'\n",
        "    deleteIntermediateFolder(intermediate_dir)\n",
        "\n",
        "    # Load datasets\n",
        "    train_image_dir = '/data/raw/Train_Test_Val_Split_Images/train'\n",
        "    test_image_dir = '/data/raw/Train_Test_Val_Split_Images/test'\n",
        "    val_image_dir = '/data/raw/Train_Test_Val_Split_Images/val'\n",
        "\n",
        "    # Set dataset parameters\n",
        "    image_size = (512, 512)\n",
        "    img_height = 512\n",
        "    img_width = 512\n",
        "    batch_size = 32\n",
        "    seed = 0\n",
        "    validation_split_ratio = 0 # 0% for validation, since the images are already split into train, test and val\n",
        "    interpolation=\"bilinear\"\n",
        "    labels=\"inferred\"\n",
        "    label_mode='int'\n",
        "    shuffle=True\n",
        "\n",
        "    # Set datasets\n",
        "    train_ds = extractDataSet(train_image_dir, labels, label_mode, image_size, batch_size, seed, True, interpolation)\n",
        "    test_ds = extractDataSet(test_image_dir, labels, label_mode, image_size, batch_size, seed, True, interpolation)\n",
        "    val_ds = extractDataSet(val_image_dir, labels, label_mode, image_size, batch_size, seed, False, interpolation)\n",
        "\n",
        "    # Review Dataset Specs\n",
        "    print(\"Train Dataset Spec: \", train_ds.element_spec)\n",
        "    print(\"Test Dataset Spec: \", test_ds.element_spec)\n",
        "    print(\"Val Dataset Spec: \", val_ds.element_spec)\n",
        "\n",
        "    # ShowClassDistributions By Dataset\n",
        "    showClassDistribution(train_ds, \"Train_DataSet\")\n",
        "    showClassDistribution(test_ds, \"Test_DataSet\")\n",
        "    showClassDistribution(val_ds, \"Val_DataSet\")\n",
        "\n",
        "    # Preprocess dataset - Normalize and Crop images\n",
        "    rotation_range = 0.2\n",
        "    width_shift_range = 0.2\n",
        "    height_shift_range = 0.2\n",
        "    shear_range = 0.2\n",
        "    zoom_range = 0.2\n",
        "    horizontal_flip = True\n",
        "    fill_mode = 'nearest'\n",
        "    data_augmentation_needed = True\n",
        "\n",
        "    preprocessed_train = train_ds.map(preprocess_images)\n",
        "    #preprocessed_test = test_ds.map(preprocess_images)\n",
        "    preprocessed_val = val_ds.map(preprocess_images)\n",
        "\n",
        "    # Preview images\n",
        "    previewImages(preprocessed_train, \"Train_DataSet\", DATA_PIPELINE_PATH)\n",
        "    previewImages(test_ds, \"Test_DataSet\", DATA_PIPELINE_PATH)\n",
        "    previewImages(preprocessed_val, \"Val_DataSet\", DATA_PIPELINE_PATH)\n",
        "\n",
        "    # Save images to pipeline\n",
        "    saveImagesToFolder(preprocessed_train, DATA_PIPELINE_PATH / 'train')\n",
        "    saveImagesToFolder(test_ds, DATA_PIPELINE_PATH / 'test')\n",
        "    saveImagesToFolder(preprocessed_val, DATA_PIPELINE_PATH / 'val')\n",
        "\n",
        "    # --- Pipeline End --"
      ]
    }
  ]
}